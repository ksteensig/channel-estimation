{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 360, 2)\n",
      "(10000, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "import numpy.linalg as linalg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# SNR is a range between min and max SNR in dB\n",
    "def generate_signal(N = 16, K = 4, L = 16, f = 2.4e9, theta_bound = np.pi/2):\n",
    "    c = 3e8 # speed of light\n",
    "    wl = c/f # wavelength (lambda)\n",
    "    d = wl/2 # uniform distance between antennas\n",
    "        \n",
    "    # antenna array\n",
    "    array = np.linspace(0,N-1,N)*d/wl\n",
    "\n",
    "    theta = rand.rand(K,1) * np.pi - np.pi/2\n",
    "\n",
    "    \n",
    "    alpha = (np.random.randn(K,1) + 1j*np.random.randn(K,1))*np.sqrt(1/2)\n",
    "        \n",
    "    response = np.exp(-1j*2*np.pi*array*np.sin(theta))*np.sqrt(1/N)    \n",
    "\n",
    "    Y = np.dot(response.T, alpha).repeat(L, axis=1)\n",
    "\n",
    "                \n",
    "    return theta, Y, alpha\n",
    "\n",
    "K = 4\n",
    "T = 2\n",
    "D = 180\n",
    "N = 64\n",
    "\n",
    "samples = 10000\n",
    "\n",
    "rads_to_vector = lambda x: np.floor((x + np.pi/2)/np.pi * D).astype(int)\n",
    "\n",
    "\n",
    "N_list = N #[16, 32, 48, 64, 96]\n",
    "\n",
    "SNR_list = [5,10,15,20,25,30]\n",
    "\n",
    "N_max = np.max(N_list)\n",
    "\n",
    "Y = np.zeros((samples, N_max, T), dtype=np.complex64)\n",
    "Theta = np.zeros((samples, K))\n",
    "Alpha = np.zeros((samples, K), dtype=np.complex64)\n",
    "\n",
    "labels = np.zeros((samples, D, T), dtype=np.complex64)\n",
    "\n",
    "for i in range(samples):\n",
    "    theta, Yi, alpha = generate_signal(N_max, K, T)\n",
    "    Y[i] = Yi\n",
    "    Theta[i] = theta.flatten()\n",
    "    \n",
    "    idx = rads_to_vector(theta)\n",
    "    labels[i, idx, :] = np.repeat(alpha, repeats=T, axis=0).reshape((K,1,T))\n",
    "\n",
    "#Y = Y.reshape((samplesT, N_max))\n",
    "#labels = labels.reshape((samples, D, T))\n",
    "    \n",
    "labels = np.concatenate([labels.real, labels.imag], axis=1)\n",
    "#labels = labels.transpose((0,2,1)) #/ np.max(np.abs(labels))\n",
    "data = Y #/ np.max(np.abs(Y))\n",
    "\n",
    "#data = np.concatenate([data.real, data.imag], axis=2)\n",
    "\n",
    "print(labels.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "import numpy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "def compute_H(theta, N, f = 2.4e9):\n",
    "    c = 3e8 # speed of light\n",
    "    wl = c/f # wavelength (lambda)\n",
    "    d = wl/2 # uniform distance between antennas\n",
    "    array = np.linspace(0,N-1,N)*d/wl\n",
    "    \n",
    "    array_response = np.exp(-1j*2*np.pi*array*np.sin(theta))*np.sqrt(1/N)  \n",
    "    return array_response.T\n",
    "\n",
    "def soft_thresh(Z, l):\n",
    "    return tf.math.sign(Z) * tf.maximum(tf.abs(Z) - l, 0.)\n",
    "\n",
    "def soft_block_thresh(Z, l, alpha, T):\n",
    "    rmse = tf.norm(Z, axis=2)\n",
    "    #print(rmse.shape)\n",
    "    rmse = tf.tile(tf.expand_dims(rmse, axis=2), multiples=[1,1,T])\n",
    "    #print(rmse.shape)\n",
    "    return (1 - l/tf.maximum(rmse, l))*Z # / (1+alpha)\n",
    "\n",
    "mul_X = lambda w, x: tf.transpose(tf.tensordot(w, x, axes=[[1],[1]]), [1,0,2])\n",
    "mul_Y = lambda w, y: tf.transpose(tf.tensordot(w, y, axes=[[1],[1]]), [1,0,2])\n",
    "\n",
    "transform_X = lambda x: tf.transpose(tf.expand_dims(x, 2), [0,3,1,2])\n",
    "transform_hgX = lambda x: tf.squeeze(tf.transpose(x, [0,2,1,3]), axis=3)\n",
    "conv_X = lambda hg, x: transform_hgX(hg(transform_X(x)))\n",
    "\n",
    "\n",
    "\n",
    "search_space = np.linspace(0,D-1, D) / D * np.pi - np.pi/2\n",
    "search_space = search_space.reshape((D, 1))\n",
    "\n",
    "H = compute_H(search_space, N)\n",
    "\n",
    "L = np.linalg.norm(H)**2\n",
    "lam_initial = 4e-3\n",
    "\n",
    "step_size = 0.5/L\n",
    "\n",
    "We_initial = 2 * step_size * H.T.conj()\n",
    "Wt_initial = np.eye(D) - H.T.conj().dot(H) * step_size\n",
    "\n",
    "class LISTA(tf.keras.Model):  #@save\n",
    "    def __init__(self, num_iter, D, N, T):\n",
    "        super(LISTA, self).__init__()\n",
    "        self.num_iter = num_iter\n",
    "        self.T = T\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        \n",
    "        self.Wt_r = tf.Variable(Wt_initial.real.copy(), dtype=tf.float32)\n",
    "        self.Wt_i = tf.Variable(Wt_initial.imag.copy(), dtype=tf.float32)\n",
    "        \n",
    "        self.We_r = tf.Variable(We_initial.real.copy(), dtype=tf.float32)\n",
    "        self.We_i = tf.Variable(We_initial.imag.copy(), dtype=tf.float32)\n",
    "        \n",
    "        self.lam_list = []\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            self.lam_list.append(tf.Variable(lam_initial, dtype=tf.float32))\n",
    "    \n",
    "        self.alpha = tf.Variable(0.1, dtype=tf.float32)\n",
    "\n",
    "    def call(self, Y):\n",
    "        \n",
    "        Y_r = tf.math.real(Y)\n",
    "        Y_i = tf.math.imag(Y)\n",
    "        \n",
    "        X_r = mul_Y(self.We_r, Y_r)\n",
    "        X_r = soft_block_thresh(X_r, self.lam_list[0], self.alpha, self.T)\n",
    "        X_i = mul_Y(self.We_i, Y_i)\n",
    "        X_i = soft_block_thresh(X_i, self.lam_list[0], self.alpha, self.T)\n",
    "\n",
    "        for i in range(1, self.num_iter):\n",
    "            X_r = mul_X(self.Wt_r, X_r) - mul_X(self.Wt_i, X_i) + mul_Y(self.We_r, Y_r) - mul_Y(self.We_i, Y_i)\n",
    "            #print(X_r.shape)\n",
    "            \n",
    "            X_r = soft_block_thresh(X_r, self.lam_list[i], self.alpha, self.T)\n",
    "            X_i = mul_X(self.Wt_r, X_i) + mul_X(self.Wt_i, X_r) + mul_Y(self.We_r, Y_i) + mul_Y(self.We_i, Y_r)\n",
    "            X_i = soft_block_thresh(X_i, self.lam_list[i], self.alpha, self.T)\n",
    "            \n",
    "        X = tf.concat([X_r, X_i], axis=1)\n",
    "        \n",
    "        return X #self.bn(X)\n",
    "\n",
    "class LISTA_Toeplitz(tf.keras.Model):  #@save\n",
    "    def __init__(self, num_iter, D, N, T):\n",
    "        super(LISTA_Toeplitz, self).__init__()\n",
    "        self.num_iter = num_iter\n",
    "        self.T = T\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        \n",
    "        self.hg_r_ = tf.keras.layers.Conv1D(1, 2*D-1, activation='linear', padding='same')\n",
    "        self.hg_i_ = tf.keras.layers.Conv1D(1, 2*D-1, activation='linear', padding='same')\n",
    "        \n",
    "        self.hg_r = tf.keras.layers.TimeDistributed(self.hg_r_)\n",
    "        self.hg_i = tf.keras.layers.TimeDistributed(self.hg_i_)\n",
    "        \n",
    "        self.We_r = tf.Variable(We_initial.real.copy(), dtype=tf.float32)\n",
    "        self.We_i = tf.Variable(We_initial.imag.copy(), dtype=tf.float32)\n",
    "        \n",
    "        self.lam_list = []\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            self.lam_list.append(tf.Variable(lam_initial, dtype=tf.float32))\n",
    "    \n",
    "        self.alpha = tf.Variable(0.1, dtype=tf.float32)\n",
    "\n",
    "    def call(self, Y):\n",
    "        \n",
    "        Y_r = tf.math.real(Y)\n",
    "        Y_i = tf.math.imag(Y)\n",
    "\n",
    "        X_r = mul_Y(self.We_r, Y_r)\n",
    "        X_r = soft_block_thresh(X_r, self.lam_list[0], self.alpha, self.T)\n",
    "        X_i = mul_Y(self.We_i, Y_i)\n",
    "        X_i = soft_block_thresh(X_i, self.lam_list[0], self.alpha, self.T)\n",
    "        \n",
    "\n",
    "        for i in range(1, self.num_iter):\n",
    "            X_r = conv_X(self.hg_r, X_r) - conv_X(self.hg_i, X_i) + mul_Y(self.We_r, Y_r) - mul_Y(self.We_i, Y_i)\n",
    "            X_r = soft_block_thresh(X_r, self.lam_list[i], self.alpha, self.T)\n",
    "            X_i = conv_X(self.hg_r, X_i) + conv_X(self.hg_i, X_r) + mul_Y(self.We_r, Y_i) + mul_Y(self.We_i, Y_r)\n",
    "            X_i = soft_block_thresh(X_i, self.lam_list[i], self.alpha, self.T)\n",
    "        \n",
    "        X = tf.concat([X_r, X_i], axis=1)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "282/282 [==============================] - 74s 252ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 2/20\n",
      "282/282 [==============================] - 70s 249ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 3/20\n",
      "282/282 [==============================] - 75s 268ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 4/20\n",
      " 33/282 [==>...........................] - ETA: 57s - loss: 0.0067"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-365-61d655a7c294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlista_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlista_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lista_model = LISTA_Toeplitz(3, D, N, T)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "adaptive_learning_rate = lambda epoch: learning_rate/(2**np.floor(epoch/10))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=1e-5)\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(adaptive_learning_rate)\n",
    "\n",
    "lista_model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "m = lista_model.fit(data, labels, batch_size=32, epochs=20, validation_split=0.1, callbacks=[stopping, lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 180)\n",
      "(1, 180, 1)\n",
      "(1, 1, 360)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5b081694c0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SNR_list = [5,10,15,20,25,30]\n",
    "\n",
    "tsamples = 1\n",
    "\n",
    "N_max = np.max(N_list)\n",
    "\n",
    "Y = np.zeros((tsamples, T, N_max), dtype=np.complex64)\n",
    "Theta = np.zeros((tsamples, K))\n",
    "Alpha = np.zeros((tsamples, K), dtype=np.complex64)\n",
    "\n",
    "labels = np.zeros((tsamples, D, T), dtype=np.complex64)\n",
    "\n",
    "for i in range(tsamples):\n",
    "    theta, Yi, alpha = generate_signal(N_max, K, T)\n",
    "    Y[i] = Yi.T\n",
    "    Theta[i] = theta.flatten()\n",
    "    \n",
    "    idx = rads_to_vector(theta)\n",
    "    labels[i, idx, :] = np.repeat(alpha, repeats=T, axis=0).reshape((K,1,T))\n",
    "\n",
    "#Y = Y.reshape((samplesT, N_max))\n",
    "labels = labels.reshape((tsamples, D, T))\n",
    "data = Y\n",
    "#data = np.concatenate([data.real, data.imag], axis=2)\n",
    "\n",
    "pred = lista_model.predict(data)\n",
    "\n",
    "pred_r, pred_i = np.array_split(pred, 2, axis=2)\n",
    "\n",
    "pred = pred_r + 1j*pred_i\n",
    "\n",
    "print(labels.shape)\n",
    "print(lista_model.predict(data).shape)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(np.abs(labels.mean(axis=2)).flatten())\n",
    "plt.plot(np.abs(pred.mean(axis=1)).flatten())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lista_model.evaluate(data_test, labels_test)#/tf.linalg.norm(labels_test)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "l = tf.Variable(0.5, dtype=tf.float32)\n",
    "\n",
    "def soft_block_thresh(Z, l, T):\n",
    "    rmse = tf.norm(Z, axis=2)\n",
    "    rmse = tf.repeat(tf.expand_dims(rmse, axis=2), repeats=T, axis=2)\n",
    "    return tf.maximum(0., 1 - l/rmse)*Z\n",
    "\n",
    "Z = tf.Variable(np.random.randn(10, 180, 2), dtype=tf.float32) * 0.3\n",
    "\n",
    "soft_block_thresh(Z, l, 2)\n",
    "\n",
    "#res\n",
    "#type(thresh)\n",
    "#thresh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00835543  0.19059657]\n",
      "  [ 0.17543498 -0.15336744]]\n",
      "\n",
      " [[ 0.08993522  0.10263053]\n",
      "  [-0.03773974  0.02691964]]\n",
      "\n",
      " [[-0.16501227  0.23341803]\n",
      "  [ 0.2254911  -0.18468982]]\n",
      "\n",
      " [[-0.17568406 -0.0419488 ]\n",
      "  [-0.01121866 -0.18006928]]], shape=(4, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def soft_block_thresh(Z, l, alpha, T):\n",
    "    rmse = tf.norm(Z, axis=2)\n",
    "    rmse = tf.expand_dims(rmse, axis=-1)\n",
    "    #print(rmse.shape)\n",
    "    rmse = tf.tile(rmse, multiples=[1, 1, T])\n",
    "    #print(rmse.shape)\n",
    "    return (1 - l/tf.maximum(rmse, l))*Z\n",
    "\n",
    "Y = np.random.randn(4,64,2)\n",
    "X = np.random.randn(4,2,180)\n",
    "We = np.random.randn(180,64)\n",
    "Wt = np.random.randn(180,180)\n",
    "\n",
    "X_ = tf.transpose(tf.expand_dims(X_, 2), [0,3,1,2])\n",
    "\n",
    "\n",
    "\n",
    "conv = tf.keras.layers.Conv1D(2, 2*180-1, activation='linear', padding='same')\n",
    "\n",
    "#td = tf.keras.layers.TimeDistributed(conv)\n",
    "\n",
    "#X = tf.transpose(tf.expand_dims(X, 2), [0,3,1,2])\n",
    "\n",
    "#X = tf.squeeze(tf.transpose(td(X), [0,2,1,3]), axis=3)\n",
    "\n",
    "#X_ = tf.squeeze(tf.transpose(td(X_), [0,2,1,3]), axis=3)\n",
    "\n",
    "print(conv(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([180])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
